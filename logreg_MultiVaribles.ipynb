{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/share/gemini/anaconda/lib/python2.7/site-packages/')\n",
    "import gemini_operations as gem_ops\n",
    "import toyplot\n",
    "import numpy as np\n",
    "import pandas\n",
    "from sklearn import linear_model, datasets, neighbors, svm, cross_validation, metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, roc_curve, auc\n",
    "from itertools import combinations\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from scipy import interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if __name__ == \"__main__\":\\n    # Set up inputs.\\n    gemini_db = \"/Users/hujingyuan/Downloads/jasper/lung_cancer.db\"\\n    annotations = [\"TCGA_LUAD\"]\\n\\n    # Get dataframe for all variants.\\n    df = gem_ops.get_genotypes_using_thresholds(gemini_db, annotations)\\n\\n    # Some checking of the data frame.\\n    print \"Number of variants: \", len(df)\\n    df = df[df[\\'num_het\\'] != 0] \\n    print \\'Remove num_het=0\\'\\n    print \\'variants: \\', len(df)\\n    print \\'TCGA: \\', len(df[df[\\'TCGA_LUAD\\'] == 1])\\n    df.to_csv(\"/Users/hujingyuan/lung_cancer.csv\")'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"if __name__ == \"__main__\":\n",
    "    # Set up inputs.\n",
    "    gemini_db = \"/Users/hujingyuan/Downloads/jasper/lung_cancer.db\"\n",
    "    annotations = [\"TCGA_LUAD\"]\n",
    "\n",
    "    # Get dataframe for all variants.\n",
    "    df = gem_ops.get_genotypes_using_thresholds(gemini_db, annotations)\n",
    "\n",
    "    # Some checking of the data frame.\n",
    "    print \"Number of variants: \", len(df)\n",
    "    df = df[df['num_het'] != 0] \n",
    "    print 'Remove num_het=0'\n",
    "    print 'variants: ', len(df)\n",
    "    print 'TCGA: ', len(df[df['TCGA_LUAD'] == 1])\n",
    "    df.to_csv(\"/Users/hujingyuan/lung_cancer.csv\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3103\n"
     ]
    }
   ],
   "source": [
    "# load the data from csv file\n",
    "df = pandas.read_csv(\"/Users/hujingyuan/lung_cancer.csv\")\n",
    "print len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data\n",
      "variants:  3103\n",
      "TCGA:  50\n",
      "Remove impact_severity=LOW\n",
      "variants:  1797\n",
      "TCGA:  50\n",
      "Remove cosmic_ids=None\n",
      "variants:  384\n",
      "TCGA:  50\n"
     ]
    }
   ],
   "source": [
    "# get rid of the obvious negative variants\n",
    "print 'Original Data'\n",
    "print 'variants: ', len(df)\n",
    "print 'TCGA: ', len(df[df['TCGA_LUAD'] == 1])\n",
    "\n",
    "df = df[df['impact_severity'] != 'LOW']\n",
    "print 'Remove impact_severity=LOW'\n",
    "print 'variants: ', len(df)\n",
    "print 'TCGA: ', len(df[df['TCGA_LUAD'] == 1])\n",
    "\n",
    "df = df[df['cosmic_ids'] != 'None']\n",
    "print 'Remove cosmic_ids=None'\n",
    "print 'variants: ', len(df)\n",
    "print 'TCGA: ', len(df[df['TCGA_LUAD'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For those columns with strings, convert them to numbers\n",
    "def cosmic_to_num(row):\n",
    "    cosmic_val = row[\"cosmic_ids\"]\n",
    "    if cosmic_val == \"None\":\n",
    "        return 0\n",
    "    else:\n",
    "        return len(cosmic_val.split(','))\n",
    "df[\"is_cosmic\"] = df.apply(cosmic_to_num, axis=1)\n",
    "\n",
    "def imp_sev_to_num(row):\n",
    "    imp_sev = row['impact_severity']\n",
    "    if imp_sev == 'LOW':\n",
    "        return 0\n",
    "    elif imp_sev == 'MED':\n",
    "        return 1\n",
    "    elif imp_sev == 'HIGH':\n",
    "        return 2\n",
    "df['impact_severityNum'] = df.apply(imp_sev_to_num, axis=1)\n",
    "\n",
    "def sift_pred_to_num(row):\n",
    "    sift_pred = row['sift_pred']\n",
    "    if sift_pred == 'None':\n",
    "        return 0\n",
    "    elif sift_pred == 'tolerated_low_confidence':\n",
    "        return 1\n",
    "    elif sift_pred == 'deleterious_low_confidence':\n",
    "        return 2\n",
    "    elif sift_pred == 'tolerated':\n",
    "        return 3\n",
    "    elif sift_pred == 'deleterious':\n",
    "        return 4\n",
    "df['sift_predNum'] = df.apply(sift_pred_to_num, axis=1)\n",
    "\n",
    "def polyphen_pred_to_num(row):\n",
    "    polyphen_pred = row['polyphen_pred']\n",
    "    if polyphen_pred == 'None':\n",
    "        return -1\n",
    "    elif polyphen_pred == 'unknown':\n",
    "        return 0\n",
    "    elif polyphen_pred == 'benign':\n",
    "        return 1\n",
    "    elif polyphen_pred == 'possibly_damaging':\n",
    "        return 2\n",
    "    elif polyphen_pred == 'probably_damaging':\n",
    "        return 3\n",
    "df['polyphen_predNum'] = df.apply(polyphen_pred_to_num, axis =1)\n",
    "allColumns = ['HP', 'num_het', 'mean_gt_depths', 'mean_gt_alt_depths', 'mean_gt_quals', 'is_cosmic', \n",
    "              'impact_severityNum', 'sift_predNum', \"polyphen_predNum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert pandas dataframe to numpy array, so it can be used for sklearn.\n",
    "def buildDF(column):\n",
    "    A = df[column]\n",
    "    X = np.asarray(A)\n",
    "    B = df['TCGA_LUAD']\n",
    "    Y = np.asarray(B)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load multiple Scikit-learn machine learning models\n",
    "def regression(model):\n",
    "    if model == 'logreg':\n",
    "        clf = linear_model.LogisticRegression(C=1e5)\n",
    "    elif model == 'knn_uniform':\n",
    "        n_neighbors = 15\n",
    "        clf = neighbors.KNeighborsClassifier(n_neighbors, weights='uniform')\n",
    "    elif model == 'knn_distance':\n",
    "        n_neighbors = 15\n",
    "        clf = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')\n",
    "    elif model == 'svm_svc':\n",
    "        C = 1\n",
    "        clf = svm.SVC(kernel='linear', C=C)\n",
    "    elif model == 'svm_rbf_svc':\n",
    "        C = 1\n",
    "        clf = svm.SVC(kernel='rbf', gamma=0.7, C=C)\n",
    "    elif model == 'svm_poly_svc':\n",
    "        C = 1\n",
    "        clf = svm.SVC(kernel='poly', degree=3, C=C)\n",
    "    elif model == 'svm_linear_svc':\n",
    "        C = 1\n",
    "        clf = svm.LinearSVC(C=C)\n",
    "    elif model == 'decision_tree':\n",
    "        C = 1\n",
    "        clf = DecisionTreeClassifier()       \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict the result with sklearn model(positive or negative variant)\n",
    "def predict(model, column):\n",
    "    X, Y = buildDF(column)\n",
    "    clf = regression(model)\n",
    "    # fi\n",
    "    clf.fit(X, Y)  \n",
    "    Y_pred = clf.predict(X)\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the precision and recall\n",
    "def presAndRecall(model, column):\n",
    "    X, Y = buildDF(column)\n",
    "    clf = regression(model)\n",
    "    Y_pred = predict(model, column)\n",
    "    precision = precision_score(Y, Y_pred)\n",
    "    recall = recall_score(Y, Y_pred)\n",
    "    return [precision, recall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crossValidation(model, column):\n",
    "    clf = regression(model)\n",
    "    X, Y = buildDF(column)\n",
    "    skf = StratifiedKFold(Y, n_folds=6)\n",
    "    PrecisionAndRecall = []\n",
    "    for train_index, test_index in skf:\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        clf.fit(X_train, Y_train)    \n",
    "        Y_pred = clf.predict(X_test)\n",
    "        precision = precision_score(Y_test, Y_pred)\n",
    "        recall = recall_score(Y_test, Y_pred)\n",
    "        PrecisionAndRecall.append((precision, recall))\n",
    "    return PrecisionAndRecall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation('knn_distance', allColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5, 0.1111111111111111),\n",
       " (0.0, 0.0),\n",
       " (0.5, 0.125),\n",
       " (0.14285714285714285, 0.375),\n",
       " (0.33333333333333331, 0.125),\n",
       " (0.66666666666666663, 0.25)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation('logreg', allColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation('knn_uniform', allColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation('svm_rbf_svc', allColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.14285714285714285, 0.1111111111111111),\n",
       " (0.16666666666666666, 0.1111111111111111),\n",
       " (0.10000000000000001, 0.125),\n",
       " (0.125, 0.5),\n",
       " (0.0, 0.0),\n",
       " (0.27272727272727271, 0.375)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidation('decision_tree', allColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.14000000000000001]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presAndRecall('logreg', allColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allModels = ['logreg', 'knn_uniform', 'knn_distance', 'decision_tree', 'svm_rbf_svc',\n",
    "             'svm_svc', 'svm_poly_svc', 'svm_linear_svc']\n",
    "presRecall = []\n",
    "for i in allModels:\n",
    "    score = crossValidation(i, allColumns)\n",
    "    presRecall.append(score)\n",
    "result = pandas.DataFrame()\n",
    "result['index'] = allModels\n",
    "result['PresRecall'] = presRecall\n",
    "print 'The first number in the array is precision, the second is recall'\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####### Generate Roc curve\n",
    "def rocCurve(column):\n",
    "    # load some data to play with\n",
    "    X, Y = buildDF(column)\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    # Add noisy features\n",
    "    random_state = np.random.RandomState(0)\n",
    "    X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
    "\n",
    "    ###############################################################################\n",
    "    # Classification and ROC analysis\n",
    "\n",
    "    # Run classifier with cross-validation and plot ROC curves\n",
    "    cv = StratifiedKFold(Y, n_folds=6)\n",
    "    classifier = svm.SVC(kernel='linear', probability=True,\n",
    "                         random_state=random_state)\n",
    "\n",
    "    mean_tpr = 0.0\n",
    "    mean_fpr = np.linspace(0, 1, len(df))\n",
    "    all_tpr = []\n",
    "\n",
    "    for i, (train, test) in enumerate(cv):\n",
    "        probas_ = classifier.fit(X[train], Y[train]).predict_proba(X[test])\n",
    "        # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = roc_curve(Y[test], probas_[:, 1])\n",
    "        mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "        mean_tpr[0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')\n",
    "\n",
    "    mean_tpr /= len(cv)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    plt.plot(mean_fpr, mean_tpr, 'k--',\n",
    "             label='Mean ROC (area = %0.2f)' % mean_auc, lw=2)\n",
    "\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rocCurve(['HP', 'num_het'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visulize the regression model. (Only available with 2 variables)\n",
    "def vis(model, column):\n",
    "    X, Y = buildDF(df, column)\n",
    "    clf, X_test, Y_test = regression(model, column)\n",
    "    \n",
    "    # Plot the boundaries\n",
    "    minList = []\n",
    "    maxList = []\n",
    "    arange = []\n",
    "    length = len(X[0])\n",
    "    i = 0\n",
    "    while i < length:\n",
    "        minValue = X[:, i].min() - 1\n",
    "        maxValue = X[:, i].max() + 1\n",
    "        minList.append(minValue)\n",
    "        maxList.append(maxValue)\n",
    "        arange.append(np.arange(minValue, maxValue, 1.0))\n",
    "        i += 1\n",
    "\n",
    "    # create a meshgrid, [x_min, m_max]x[y_min, y_max]\n",
    "    shape = np.meshgrid(*arange)\n",
    "    ravel = [x.ravel() for x in shape]\n",
    "    Z = clf.predict(np.column_stack((ravel)))\n",
    "    \n",
    "    # change the shape of result into meshgrid\n",
    "    xx = shape[0]\n",
    "    Z = Z.reshape(xx.shape)\n",
    "   \n",
    "    \n",
    "    \n",
    "    # Put the result into a color plot\n",
    "    xx = shape[0]\n",
    "    yy = shape[1]\n",
    "    plt.figure(1, figsize=(4, 3))\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "    # Plot scatterpoints\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "    plt.xlabel(column[0])\n",
    "    plt.ylabel(column[1])\n",
    "\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print out the prediction alongside the original value\n",
    "def validate(model, column):\n",
    "    Y_pred= predict(model, column)\n",
    "    data = df[column]\n",
    "    data['TCGA_LUAD'] = df['TCGA_LUAD']\n",
    "    data['Predict'] = Y_pred\n",
    "    data = data.sort(['Predict', 'TCGA_LUAD'], ascending = [False, False])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first number in the array is precision, the second is recall\n",
      "(mean_gt_quals, impact_severityNum)                    [1.0, 0.98]\n",
      "(is_cosmic, sift_predNum)                   [0.705882352941, 0.24]\n",
      "(num_het, is_cosmic)                        [0.894736842105, 0.34]\n",
      "(mean_gt_depths, impact_severityNum)                   [1.0, 0.94]\n",
      "(HP, mean_gt_alt_depths)                                [1.0, 0.9]\n",
      "(impact_severityNum, sift_predNum)                      [0.0, 0.0]\n",
      "(mean_gt_depths, sift_predNum)                         [1.0, 0.94]\n",
      "(HP, impact_severityNum)                                [0.0, 0.0]\n",
      "(mean_gt_alt_depths, sift_predNum)                     [1.0, 0.86]\n",
      "(mean_gt_quals, polyphen_predNum)                      [1.0, 0.98]\n",
      "(is_cosmic, polyphen_predNum)               [0.764705882353, 0.26]\n",
      "(mean_gt_quals, is_cosmic)                              [1.0, 1.0]\n",
      "(HP, is_cosmic)                             [0.722222222222, 0.26]\n",
      "(HP, num_het)                                        [0.875, 0.14]\n",
      "(mean_gt_depths, is_cosmic)                             [1.0, 1.0]\n",
      "(mean_gt_alt_depths, polyphen_predNum)                  [1.0, 0.9]\n",
      "(num_het, polyphen_predNum)                             [1.0, 0.1]\n",
      "(mean_gt_depths, polyphen_predNum)                     [1.0, 0.96]\n",
      "(sift_predNum, polyphen_predNum)                        [0.0, 0.0]\n",
      "(HP, mean_gt_depths)                                    [1.0, 1.0]\n",
      "(mean_gt_quals, sift_predNum)                          [1.0, 0.98]\n",
      "(HP, sift_predNum)                                      [0.0, 0.0]\n",
      "(HP, mean_gt_quals)                                     [1.0, 1.0]\n",
      "(impact_severityNum, polyphen_predNum)                  [0.0, 0.0]\n",
      "(mean_gt_alt_depths, is_cosmic)                        [1.0, 0.98]\n",
      "(is_cosmic, impact_severityNum)                       [0.75, 0.12]\n",
      "(mean_gt_depths, mean_gt_alt_depths)                    [1.0, 1.0]\n",
      "(mean_gt_depths, mean_gt_quals)                         [1.0, 1.0]\n",
      "(num_het, sift_predNum)                                [1.0, 0.12]\n",
      "(HP, polyphen_predNum)                                 [1.0, 0.02]\n",
      "(num_het, mean_gt_depths)                              [1.0, 0.96]\n",
      "(num_het, impact_severityNum)                [0.714285714286, 0.1]\n",
      "(mean_gt_alt_depths, impact_severityNum)                [1.0, 0.8]\n",
      "(mean_gt_alt_depths, mean_gt_quals)                     [1.0, 1.0]\n",
      "(num_het, mean_gt_quals)                               [1.0, 0.98]\n",
      "(num_het, mean_gt_alt_depths)                           [1.0, 0.9]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Which two columns are good at predicting the result\n",
    "listOfColumns = list(combinations(allColumns, 2))\n",
    "print 'The first number in the array is precision, the second is recall'\n",
    "presAndRecallDict = {}\n",
    "for i in listOfColumns:    \n",
    "    presAndRecallDict[i] = presAndRecall('knn_distance', list(i))\n",
    "s  = pandas.Series(presAndRecallDict, index=presAndRecallDict.keys())\n",
    "print s  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
